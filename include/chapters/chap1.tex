\chapter{Nozioni Fondamentali}
L'obiettivo di questo capitolo è quello di presentare i concetti di base
che vengono utilizzati nel seguito di questo lavoro e, più in generale,
nell'ambito dell'ottimizzazione matematica.

\section{Introduzione}
Ottimizzare significa risolvere un problema trovando la soluzione migliore
nell'insieme delle soluzioni che abbiamo a disposizione. Il desiderio di
scegliere la soluzione migliore è così comune che il concetto di
ottimizzazione è parte integrante di ogni ambito che richieda di risolvere
problemi decisionali. Nella pratica, risolvere un problema decisionale
significa assegnare valori alle variabili che lo caratterizzano, con
la finalità di ottimizzare una grandezza, rispettando un insieme di
vincoli che limitano le scelte dei valori per queste variabili. La
grandezza da ottimizzare e i vincoli possono essere spesso
rappresentati come funzioni delle variabili coinvolte e questo ci permette
di definire e utilizzare un modello matematico per descrivere il problema che stiamo
considerando. La formulazione di un modello dovrebbe essere
sufficientemente complessa da rappresentare accuratamente il problema cui
si riferisce e, allo stesso tempo, abbastanza semplice da renderlo
trattabile con gli strumenti risolutivi disponibili.

La ricerca operativa è un ramo della matematica applicata che impiega
metodi e modelli matematici per risolvere problemi decisionali. Di fronte
ad un problema del mondo reale, il primo passo è quello di trovare un modello
matematico che sia in grado di descriverlo. Successivamente si procede con
l'applicazione dei metodi di ottimizzazione per trovare la soluzione
migliore. Infine, la soluzione trovata va interpretata e adattata al
problema reale. Questo processo può anche essere iterato, con l'obiettivo di
raffinare il modello di riferimento e ottenere
soluzioni sempre più accurate.

Non tutte le classi di problemi di ottimizzazione si possono risolvere
all'ottimo in un tempo ragionevole e questo ha determinato lo sviluppo di
algoritmi euristici.

\section{Problemi di Ottimizzazione}
Un problema di ottimizzazione $\mathcal{P}$ può essere definito con la
formulazione generale

\begin{equation}
    \mathcal{P}\colon
    \begin{cases}
        \text{$\min$ (or $\max$)} & f(\vec{x}) \\
                                  & \mathcal{S} \\
                                  & \vec{x} \in \mathcal{D}
    \end{cases}\\[10pt]
\end{equation}
dove $f(\vec{x})$ è una funzione a valori reali nelle variabili $\vec{x} =
[x_{1}\, \ldots \, x_{n}]^T \in \mathcal{D} = D_{1} \times
\cdots \times D_{n}$ con $x_{j} \in D_{j}\,\,\,\forall j\colon 1 \le j
\le n,\, n \in \mathbb{N}$ e $\mathcal{S}$ è un insieme finito di vincoli.
Formalmente, un vincolo $c \in \mathcal{S}$ è una funzione che coinvolge un
sottoinsieme delle variabili del problema e che può assumere i valori vero
o falso, corrispondenti alla condizione di vincolo soddisfatto o violato,
rispettivamente.

Il massimo valore di una funzione $f(\vec{x})$ è il minimo valore della
funzione $-f(\vec{x})$, a meno del segno. Per questo motivo possiamo
limitarci a studiare i problemi di minimo senza perdere di generalità.
Tutte le considerazioni che faremo sono valide, con opportune modifiche,
anche per i problemi di massimo.

\begin{definition}
Dato un problema di ottimizzazione $\mathcal{P}$, ogni $\vec{x} \in
\mathcal{D}$ si dice soluzione di $\mathcal{P}$. Una soluzione di
$\mathcal{P}$ che soddisfi tutti i vincoli in $\mathcal{S}$ si dice
ammissibile per $\mathcal{P}$.
\end{definition}
Per riferirci all'insieme di tutte le soluzioni ammissibili per un problema
di ottimizzazione $\mathcal{P}$, utilizzeremo la notazione
$F(\mathcal{P})$.

La caratterizzazione del dominio $\mathcal{D}$ fornisce una
classificazione immediata dei problemi di ottimizzazione.

\begin{itemize}
    \item Se il dominio $\mathcal{D}$ è un insieme discreto, il problema è
        detto di \textit{ottimizzazione discreta}.
    \item Se il dominio $\mathcal{D}$ è un insieme continuo, il problema è
        detto di \textit{ottimizzazione continua}.
\end{itemize}
Inoltre, nel caso particolare di un dominio $\mathcal{D}$ che sia un
insieme discreto e finito, si parla di \textit{ottimizzazione
combinatoria}.

\begin{definition}
Sia $\mathcal{P}$ un problema di ottimizzazione. Una soluzione ammissibile
$\vec{x^{\star}} \in F(\mathcal{P})$ si dice ottima per $\mathcal{P}$ se
\[
    f(\vec{x^{\star}}) \le f(\vec{x}) \quad \forall \vec{x} \in
    F(\mathcal{P}).
\]
\end{definition}
Un problema di ottimizzazione $\mathcal{P}$ si dice impossibile
(\textit{infeasible}) quando non ammette soluzioni ammissibili, ossia
quando $F(\mathcal{P}) = \varnothing$. Diciamo invece che $\mathcal{P}$ è
illimitato (\textit{unbounded}) quando non esiste alcun limite inferiore a
$f(\vec{x})$, per $\vec{x} \in F(\mathcal{P})$. Se esiste una soluzione
$\vec{x^{\star}} \in F(\mathcal{P})$ ottima per $\mathcal{P}$, allora diciamo
che $\mathcal{P}$ ammette ottimo finito. La funzione $f(\vec{x})$ è
generalmente chiamata funzione obiettivo e il valore $f(\vec{\bar{x}})$ è
tipicamente noto come costo associato alla soluzione $\vec{\bar{x}} \in
F(\mathcal{P})$.

Un problema di ottimizzazione si dice risolto quando si trova una soluzione
ottima, e si dimostra che è tale, oppure quando si riesce a dimostrare che
il problema è impossibile o illimitato.

\subsection{Restrizioni e Rilassamenti}

Procediamo ora a definire due concetti che sono usati in larga misura
nell'ambito dell'ottimizzazione matematica.

\begin{definition}[Restrizione]
    Sia $\mathcal{P}$ un problema di ottimizzazione. Si definisce
    restrizione di $\mathcal{P}$ un problema di ottimizzazione
    $\mathcal{P}'$ ottenuto da $\mathcal{P}$ aggiungendo vincoli.
\end{definition}
Aggiungere vincoli ad un problema significa ridurre lo spazio delle sue
soluzioni ammissibili. Formalmente, se $\mathcal{P}'$ è una restrizione di
$\mathcal{P}$, allora $F(\mathcal{P}') \subseteq F(\mathcal{P})$. Di
conseguenza, se $\vec{\bar{x}}$ è una generica soluzione ammissibile per
$\mathcal{P}'$, ossia $\vec{\bar{x}} \in F(\mathcal{P}')$, allora
$\vec{\bar{x}}$ è una soluzione ammissibile per $\mathcal{P}$, cioè
$\vec{\bar{x}} \in F(\mathcal{P})$. Inoltre, è facile verificare che il
costo associato a $\vec{\bar{x}}$ fornisce un limite superiore
(\textit{upper bound}) al valore ottimo di $\mathcal{P}$, ossia
$f(\vec{x^{\star}}) \le f(\vec{\bar{x}})$, con $\vec{x^{\star}} \in
F(\mathcal{P})$ soluzione ottima per $\mathcal{P}$.

Infine, è immediato dimostrare che se $\mathcal{P}$ è impossibile, ossia
$F(\mathcal{P}) = \varnothing$, allora anche ogni sua restrizione
$\mathcal{P}'$ è impossibile, cioè $F(\mathcal{P}') = \varnothing$. Non
vale il viceversa.

\begin{definition}[Rilassamento]
Sia $\mathcal{P}$ un problema di ottimizzazione. Si definisce rilassamento
di $\mathcal{P}$ un problema di ottimizzazione $\mathcal{R}$ ottenuto da
$\mathcal{P}$ rimuovendo alcuni vincoli e/o sostituendo la funzione
obiettivo $f(\vec{x})$ di $\mathcal{P}$ con una sua approssimazione
inferiore $g(\vec{x})$. Formalmente, $\mathcal{R}$ è un rilassamento di
$\mathcal{P}$ se $F(\mathcal{P}) \subseteq F(\mathcal{R})$ e $g(\vec{x})
\le f(\vec{x}) \,\,\, \forall \vec{x} \in F(\mathcal{P})$.
\end{definition}
Si verifica immediatamente che se $\mathcal{R}$ è impossibile, ossia
$F(\mathcal{R}) = \varnothing$, allora anche $\mathcal{P}$ è impossibile,
cioè $F(\mathcal{P}) = \varnothing$. Non vale il viceversa. Inoltre, è
facile dimostrare che se $\vec{\bar{x}} \in F(\mathcal{R})$ è ottima per
$\mathcal{R}$, allora $g(\vec{\bar{x}})$ fornisce un limite inferiore
(\textit{lower bound}) al valore ottimo di $\mathcal{P}$, ossia
$f(\vec{x^{\star}}) \ge g(\vec{\bar{x}})$, con $\vec{x^{\star}} \in
F(\mathcal{P})$ soluzione ottima per $\mathcal{P}$.  Infine, se la
soluzione ottima $\vec{x^{\star}} \in F(\mathcal{R})$ di $\mathcal{R}$ è
ammissibile per $\mathcal{P}$, con $g(\vec{x^{\star}}) =
f(\vec{x^{\star}})$, allora $\vec{x^{\star}}$ è soluzione ottima per
$\mathcal{P}$.

\subsection{Il Processo di Ricerca}
Dato un problema di ottimizzazione $\mathcal{P}$, la ricerca è il processo
che consiste nel risolvere una sequenza finita $\mathcal{P}_1, \ldots,
\mathcal{P}_m$ di restrizioni di $\mathcal{P}$. L'intuizione alla base
della ricerca è la seguente. Aggiungendo vincoli al problema di partenza,
con l'obiettivo di creare una sequenza di restrizioni, cerchiamo di ottenere
problemi di ottimizzazione che siano più semplici da risolvere rispetto al
problema $\mathcal{P}$ di partenza.

\begin{definition}[Ricerca Esaustiva]
Sia $\mathcal{P}$ un problema di ottimizzazione. Si definisce ricerca
esaustiva il processo di ricerca su una sequenza finita
$\mathcal{P}_1, \ldots, \mathcal{P}_m$ di restrizioni di $\mathcal{P}$ che
copre tutto lo spazio delle soluzioni ammissibili di $\mathcal{P}$.
Formalmente, deve valere che
\[
    \bigcup_{i=1}^{m} F(\mathcal{P}_i) = F(\mathcal{P}).
\]
\end{definition}
Quando una ricerca non è esaustiva, diciamo che è euristica.
Una ricerca esaustiva ci permette di risolvere un problema di
ottimizzazione $\mathcal{P}$ trovando le soluzioni di tutte le restrizioni
$\mathcal{P}_i$ e scegliendo quella migliore.

La forma più semplice di ricerca esaustiva prende il nome di
\textit{generate-and-test} e consiste nel generare esplicitamente tutte le
soluzioni $\vec{x} \in \mathcal{D}$ di $\mathcal{P}$, verificare quali
soddisfano i vincoli del problema e scegliere tra queste quella migliore.
Questa strategia è applicabile in pratica solo a una classe ristretta di
problemi di ottimizzazione e non è molto efficiente.

Una tipologia di ricerca più evoluta è quella che prende il nome di
\textit{tree-search} e che sfrutta una struttura ad albero per esplorare lo
spazio delle soluzioni ammissibili di un problema. Questo tipo di ricerca è
alla base di tutti gli algoritmi enumerativi che vengono usati in pratica
per risolvere problemi di ottimizzazione. L'idea è quella dividere
ricorsivamente lo spazio di ricerca delle soluzioni ammissibili di
$\mathcal{P}$ creando delle restrizioni in una struttura ad albero, in cui
i nodi foglia corrispondono a restrizioni sufficientemente facili da
risolvere. Una strategia di ricerca di questo tipo è spesso combinata con
il concetto di rilassamento, con l'obiettivo di semplificare la risoluzione
delle restrizioni.

Un processo di ricerca esaustiva non è necessariamente l'approccio migliore
in tutte le situazioni. Esistono classi di problemi per cui ha poco senso
provare a trovare una soluzione ottima esplorando tutto lo spazio delle
soluzioni ammissibili, ad esempio perché questo spazio sarebbe troppo
grande oppure perché il tempo di computazione richiesto sarebbe troppo
elevato.  In questi casi è molto più conveniente utilizzare algoritmi
euristici, il cui obiettivo non è tanto quello di risolvere un  problema
all'ottimo ma piuttosto quello di fornire una soluzione accettabile in
tempi ragionevoli, relativamente allo specifico contesto applicativo.

\section{Programmazione Lineare}
La programmazione lineare rappresenta uno dei paradigmi fondamentali
nell'ambito dell'ottimizzazione, poiché si applica naturalmente ad un'ampia
classe di problemi del mondo reale, che risultano quindi facili da
modellare. Inoltre, nel corso del tempo sono stati sviluppati algoritmi in
grado di risolvere efficientemente problemi di programmazione lineare che
coinvolgono un numero molto elevato di variabili e vincoli.

Un problema di programmazione lineare (LP), è un problema di ottimizzazione
in cui la funzione obiettivo e vincoli sono funzioni lineari. Per un problema
di programmazione lineare $\mathcal{P}$ con $n$ variabili e $m$ vincoli si
può utilizzare la formulazione generale

\begin{equation}
\mathcal{P}\colon
\setlength{\arraycolsep}{2pt}
\left\{\begin{array}{rrcccccc}
\min & z\,\, &=& \multicolumn{5}{c}{c_{1}\,x_{1}+\cdots+c_{n}\,x_{n}} \\[15pt]
     &  a_{11}\,x_{1} &+ &\cdots &+ &a_{1n}\,x_{n} &\sim &b_{1}       \\
     & \multicolumn{1}{c}{\vdots} &&&&\vdots&& \vdots                 \\
     &  a_{m1}\,x_{1} &+ &\cdots &+ &a_{mn}\,x_{n} &\sim &b_{m}       \\[15pt]
     & \multicolumn{7}{l}{\ell_j \le x_{j} \le u_{j} \;\;\, \forall j\colon
     1 \le j \le n}
\end{array}\right.\\[10pt]
\end{equation}
dove $\sim\,\,\in \{ \le, =, \ge \}$, $\ell_j \in \mathbb{R} \cup
\{-\infty\}$ e $u_{j} \in \mathbb{R} \cup \{+\infty\}$, con $c_{k} \in
\mathbb{R} \,\,\, \forall k\colon 1 \le k \le n$, $a_{ij} \in \mathbb{R}
\,\,\, \forall i,j\colon 1 \le i \le m,\, 1 \le j \le n$ e $b_{i} \in
\mathbb{R} \,\,\, \forall i\colon 1 \le i \le m$. Le variabili del
problema hanno come dominio intervalli (eventualmente illimitati) di
$\mathbb{R}$ e la funzione obiettivo può essere scritta nella forma compatta
\begin{equation}
    z = \sum_{k=1}^{n} c_{k}\,x_{k}\,.
\end{equation}
Similmente, il generico vincolo può essere scritto come
\begin{equation}
    \sum_{j=1}^{n}a_{ij}\,x_{j} \sim b_{i} \qquad \forall i\colon 1 \le i \le m
.\end{equation}

La proprietà di linearità della funzione obiettivo e dei vincoli permette
di utilizzare la teoria dell'analisi convessa come base nello sviluppo di
algoritmi risolutivi per problemi di programmazione lineare. In aggiunta,
questa proprietà semplifica significativamente il processo attraverso cui è
possibile ottenere formulazioni alternative, tutte equivalenti tra loro,
relativamente ad uno stesso problema di programmazione lineare.

\subsection{Interpretazione Geometrica}
Prima di procedere con l'analisi della geometria di un problema di
programmazione lineare, è essenziale definire i concetti di semispazio
affine, iperpiano e poliedro.

\begin{definition}
    Siano $\vec{x} \in \mathbb{R}^n,\ \vec{a} \in \mathbb{R}^n$ e $a_{0}
    \in \mathbb{R}$. Si definiscono semispazio chiuso e iperpiano gli
    insiemi
    \(
        \{ \vec{x} \in \mathbb{R}^n \mid \vec{a}^T\vec{x} \le a_{0}\}
    \)
    e
    \(
        \{ \vec{x} \in \mathbb{R}^n \mid \vec{a}^T\vec{x} = a_{0}\},
    \)
    rispettivamente.
\end{definition}
Si può dimostrare che un semispazio chiuso è un insieme convesso. Lo stesso
vale per un iperpiano.  Informalmente, un insieme $\mathcal{C} \subseteq
\mathbb{R}^n$ si dice convesso quando, per ogni coppia di punti
dell'insieme, il segmento che li congiunge è interamente contenuto in
$\mathcal{C}$.
\begin{definition}\label{def:poly}
    Si definisce poliedro un insieme $\mathcal{P} \subseteq \mathbb{R}^n$
    che è intersezione di un numero finito di semispazi chiusi e iperpiani.
\end{definition}
Da questa definizione si verifica facilmente che un poliedro è un insieme
convesso, poiché intersezione di un numero finito di insiemi convessi.
Inoltre, un poliedro limitato viene chiamato politopo.

Le definizioni appena presentate ci permettono di concludere che, per il
generico problema di programmazione lineare, lo spazio delle soluzioni
ammissibili è un insieme convesso e, nello specifico, un poliedro.

La \cref{def:poly} è chiamata descrizione esterna di un poliedro. Esiste
anche un modo alternativo di definire un poliedro, che fa uso del concetto
di vertice e che prende il nome di descrizione interna. Informalmente, un
vertice di un insieme convesso è un punto che non può essere espresso come
combinazione lineare convessa stretta di altri due punti dell'insieme.
Consideriamo ora la descrizione interna di un politopo.

%% FIX FROM HERE

\begin{theorem}
    Siano $\mathcal{P} \subset \mathbb{R}^n$ un politopo e
    $\mathcal{V} = \{ \vec{x}_1, \ldots, \vec{x}_k\}$ l'insieme dei suoi
    vertici. Allora ogni punto $\vec{x} \in \mathcal{P}$ può essere
    espresso come combinazione lineare convessa dei punti di $\mathcal{V}$.
    Formalmente,
    \[
        \vec{x} \in \mathcal{P} \iff
            \vec{x} = \sum_{j=1}^{k} \lambda_j \vec{x}_j\,, \text{ con }
            \sum_{j=1}^{k} \lambda_j = 1,\,
            \lambda_j \ge 0 \,\,\, \forall j\colon 1 \le j \le k.
    \]
\end{theorem}
La descrizione interna di un politopo è uno strumento importante perché
permette di dimostrare il teorema fondamentale della programmazione
lineare, riportato di seguito.

\begin{LPTheorem}
Consideriamo il problema di programmazione lineare della
forma
\(
    \min \{\vec{c}^T\vec{x} \mid
    \vec{x} \in \mathcal{P} \},
\)
dove $\mathcal{P} \subset \mathbb{R}^n$ è un politopo che rappresenta la
regione ammissibile, cioè l'insieme dei punti che soddisfano tutti i
vincoli che definiscono $\mathcal{P}$, e $\vec{c} \in \mathbb{R}^n$. Allora,
se il problema ammette ottimo finito, esiste almeno un vertice di
$\mathcal{P}$ che è soluzione ottima.
\end{LPTheorem}
Questo teorema ci permette di concludere che a prescindere dal numero delle
soluzioni ottime di un problema, è sempre possibile trovarne una in
corrispondenza di uno dei vertici del politopo $\mathcal{P}$ che definisce
la regione ammissibile. Quindi possiamo ridurre lo spazio di ricerca delle
soluzioni e limitarci a ispezionare solamente i vertici di $\mathcal{P}$.
Ed è proprio questa l'intuizione che pone le basi per lo sviluppo
dell'algoritmo del simplesso, uno degli algoritmi maggiormente impiegati
nella risoluzione di problemi di programmazione lineare.

Il teorema fondamentale può essere esteso al caso generale di problemi di
programmazione lineare in cui la regione ammissibile è un poliedro (con
almeno un vertice) e non necessariamente un politopo. L'ipotesi
sull'esistenza della soluzione ottima deve comunque valere, per evitare che
il problema possa risultare illimitato o impossibile.

\subsection{Formulazioni Equivalenti}
Un problema di programmazione lineare può essere espresso attraverso
molteplici formulazioni differenti, tutte equivalenti tra loro. Inoltre,
con opportune trasformazioni, è sempre possibile passare da una
formulazione all'altra. Per il generico problema di ottimizzazione
$\mathcal{P}$ con $n$ variabili e $m$ vincoli, le due forme maggiormente
utilizzate sono la forma standard e quella canonica, riportate di seguito.
\\
\begin{subequations}
\hspace*{.08\textwidth}
\begin{minipage}{.3\textwidth}
\begin{align}\notag
    \begin{cases}
        \,\min & \vec{c}^T \vec{x} \\
             & \vec{A} \vec{x} = \vec{b} \\
             & \vec{x} \ge 0
    \end{cases}\\[7pt] \text{Forma Standard}
\end{align}
\end{minipage}\hspace{.1\textwidth}
\begin{minipage}{.3\textwidth}
    \begin{align}\notag
    \begin{cases}
        \,\min & \vec{c}^T \vec{x} \\
             & \vec{A} \vec{x} \ge \vec{b} \\
             & \vec{x} \ge 0
    \end{cases}\\[7pt] \text{Forma Canonica}
\end{align}
\end{minipage}\\[10pt]
\end{subequations}
dove $\vec{x} \in \mathbb{R}^n$, con $\vec{c} \in \mathbb{R}^n,\ \vec{A}
\in \mathcal{M}_{m \times n}^{\mathbb{R}}$ e $\vec{b} \in \mathbb{R}^m$.
Le trasformazioni necessarie per passare da una forma all'altra consistono
nell'introduzione di variabili ausiliarie e la convenienza di una forma
rispetto all'altra dipende dallo specifico contesto applicativo.

\subsection{L'algoritmo del Simplesso}
\subsection{L'algoritmo del Punto Interno}
\subsection{Dualità}
\subsection{Rilassamento Lagrangiano}

\section{Programmazione Lineare Intera}

